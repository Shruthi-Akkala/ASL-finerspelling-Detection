{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dependencies"
      ],
      "metadata": {
        "id": "fIVjoPjsMPgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from tqdm import tqdm\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "JR_5cjUbKrm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining necessary functions"
      ],
      "metadata": {
        "id": "q7PTxhv4MSNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Handland takes the mediapipe output landmarks, collates all the coordinates and flattens it to create an array of size 63\n",
        "\n",
        "def handland(results):\n",
        "    hl = np.array([[landmark.x,landmark.y,landmark.z] for landmark in results.multi_hand_landmarks[0].landmark]).flatten() if results.multi_hand_landmarks else np.zeros(63)\n",
        "    return hl\n",
        "\n",
        "def handscore(results):\n",
        "    sc = results.multi_handedness[0].classification[0].score\n",
        "    return sc\n",
        "\n",
        "#Choose is basically the combined model. We have three different custom models and the combination of the three seems to be working better.\n",
        "\n",
        "def choose(a,b,c):\n",
        "    if a != '':\n",
        "        a = ord(a)\n",
        "        b = ord(b)\n",
        "        c = ord(c)\n",
        "        if (b-c) == 0:\n",
        "            return chr(b)\n",
        "        else:\n",
        "            return chr(a)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "\n",
        "#Augmentation Function\n",
        "\n",
        "from PIL import Image as PILImage\n",
        "def augment_image(image):\n",
        "    # Read the original image\n",
        "    original_image = image\n",
        "\n",
        "    # Convert image from BGR to RGB\n",
        "    original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Initialize the list to store augmented images\n",
        "    augmented_images = [original_image_rgb]\n",
        "\n",
        "    # Flip the image horizontally\n",
        "    # flipped_image = cv2.flip(original_image_rgb, 1)\n",
        "    # augmented_images.append(flipped_image)\n",
        "\n",
        "    # Rotate the image by custom angles\n",
        "    rotation_angles = np.arange(-15,16,10)\n",
        "    for angle in rotation_angles:\n",
        "        rotated_image = PILImage.fromarray(original_image_rgb)\n",
        "        rotated_image = rotated_image.rotate(angle)\n",
        "        rotated_image = np.array(rotated_image)\n",
        "        augmented_images.append(rotated_image)\n",
        "\n",
        "    # GaussianBlur the image\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(original_image_rgb, (5 , 5), 0)\n",
        "    augmented_images.append(blurred_image)\n",
        "\n",
        "    return augmented_images"
      ],
      "metadata": {
        "id": "0syIY18HKznq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mediapipe Functions"
      ],
      "metadata": {
        "id": "VMojh0UgMq4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grabbing the Holistic Model from Mediapipe and\n",
        "# Initializing the Model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic_model = mp_holistic.Holistic(\n",
        "\tmin_detection_confidence=0.1,\n",
        "\tmin_tracking_confidence=0.1\n",
        ")\n",
        "\n",
        "# Initializing the drawing utils for drawing the facial landmarks on image\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing_styles = mp.solutions.drawing_styles"
      ],
      "metadata": {
        "id": "Nm4QzItEK2JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the model weights"
      ],
      "metadata": {
        "id": "0DDT2bN1PrgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We load the weights for all the 3 custom models here\n",
        "\n",
        "#The efficiency of the model is decreasing with increase in model number i.e. Model 1 is suppposed to be the best and Model 3 is worst\n",
        "#Model 1 is trained on the custom train dataset we created\n",
        "#Model 2 is trained on the Augmented Dataset we obtained from the Yolo  Train Data\n",
        "#Model 3 is trained on a much bigger dataset + augmentation, but the quality of the dataset was not up to the mark and it often used wrong signs\n",
        "\n",
        "def baseline_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(46, input_dim=63, activation='relu', kernel_regularizer=regularizers.l1(0.01)))\n",
        "  model.add(Dense(26, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model1 = baseline_model()\n",
        "model1.load_weights(\"wcdata_2layers.h5\")\n",
        "model2 = baseline_model()\n",
        "model2.load_weights(\"augdata_2layer.h5\")\n",
        "model3 = baseline_model()\n",
        "model3.load_weights(\"bigdataASLNN26.h5\")"
      ],
      "metadata": {
        "id": "SIJXb8dZPWW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading custom test dataset"
      ],
      "metadata": {
        "id": "OvsjA0AeWIOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Let = np.loadtxt('custom_test_data_mp.txt')\n",
        "Testlabel = np.loadtxt('custom_test_labels.txt',dtype = str)"
      ],
      "metadata": {
        "id": "PaLjMfHBL5hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the models on the test dataset"
      ],
      "metadata": {
        "id": "ZiQEV0NgWJ8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = [chr(np.argmax(i)+65) for i in model1(Let)]\n",
        "pred2 = [chr(np.argmax(i)+65) for i in model2(Let)]\n",
        "pred3 = [chr(np.argmax(i)+65) for i in model3(Let)]\n",
        "pred4 = [choose(pred1[i],pred2[i],pred3[i]) for i in range(len(Let))]"
      ],
      "metadata": {
        "id": "V2cluhIgMXro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix Calculations"
      ],
      "metadata": {
        "id": "hzS7d7d5Wdr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm1 = confusion_matrix(Testlabel,pred1)\n",
        "cm2 = confusion_matrix(Testlabel,pred2)\n",
        "cm3 = confusion_matrix(Testlabel,pred3)\n",
        "cm4 = confusion_matrix(Testlabel,pred4)\n",
        "\n",
        "plt.title('Model 3')\n",
        "sns.heatmap(cm3)\n",
        "plt.show()\n",
        "plt.title('Model 2')\n",
        "sns.heatmap(cm2)\n",
        "plt.show()\n",
        "plt.title('Model 1')\n",
        "sns.heatmap(cm1)\n",
        "plt.show()\n",
        "plt.title('Combined Model')\n",
        "sns.heatmap(cm4)"
      ],
      "metadata": {
        "id": "MnL8Q6WaVrZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Calculation"
      ],
      "metadata": {
        "id": "y1qIhdloWhpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc1,acc2,acc3,acc4 = 0,0,0,0\n",
        "\n",
        "for i in range(len(Testlabel)):\n",
        "    if pred1[i] == Testlabel[i]:\n",
        "        acc1+=1\n",
        "    if pred2[i] == Testlabel[i]:\n",
        "        acc2+=1\n",
        "    if pred3[i] == Testlabel[i]:\n",
        "        acc3+=1\n",
        "    if pred4[i] == Testlabel[i]:\n",
        "        acc4+=1\n",
        "acc1/= len(Testlabel)\n",
        "acc2/= len(Testlabel)\n",
        "acc3/= len(Testlabel)\n",
        "acc4/= len(Testlabel)\n",
        "\n",
        "acc1,acc2,acc3,acc4"
      ],
      "metadata": {
        "id": "nKTsT4nHMayQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall Calculation"
      ],
      "metadata": {
        "id": "5ICEdAEdWkdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1,r2,r3,r4 = 0,0,0,0\n",
        "for i in range(len(cm1)):\n",
        "    r1 += (cm1[i,i]/np.sum(cm1[i]))\n",
        "    r2 += (cm2[i,i]/np.sum(cm2[i]))\n",
        "    r3 += (cm3[i,i]/np.sum(cm3[i]))\n",
        "    r4 += (cm4[i,i]/np.sum(cm4[i]))\n",
        "r3,r2,r1,r4 = r3/26,r2/26,r1/26,r4/26"
      ],
      "metadata": {
        "id": "UONNV1wAMcD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision Calculation"
      ],
      "metadata": {
        "id": "O8HKswxoWmLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1,p2,p3,p4 = 0,0,0,0\n",
        "cm1 = cm1.T\n",
        "cm2 = cm2.T\n",
        "cm3 = cm3.T\n",
        "cm4 = cm4.T\n",
        "for i in range(len(cm1)):\n",
        "    p1 += (cm1[i,i]+0.001)/(np.sum(cm1[i])+0.001*len(cm1[i]))\n",
        "    p2 += (cm2[i,i]+0.001)/(np.sum(cm2[i])+0.001*len(cm2[i]))\n",
        "    p3 += (cm3[i,i]+0.001)/(np.sum(cm3[i])+0.001*len(cm3[i]))\n",
        "    p4 += (cm4[i,i]/np.sum(cm4[i]))\n",
        "p3,p2,p1,p4 = p3/26,p2/26,p1/26,p4/26"
      ],
      "metadata": {
        "id": "s4CzcT9FVxfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F-1 score calculation"
      ],
      "metadata": {
        "id": "MAOUytJcWpNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1,f2,f3,f4 = (2*p1*r1)/(p1+r1), (2*p2*r2)/(p2+r2), (2*p3*r3)/(p3+r3), (2*p4*r4)/(p4+r4)\n",
        "f3,f2,f1,f4"
      ],
      "metadata": {
        "id": "QJ7xUeVvVxxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing  Scores like a table"
      ],
      "metadata": {
        "id": "bRGGsIjGWrOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\t \\t Accuracies: \\t\\t Average Precision: \\t\\t Average Recall \\t\\t Averafe F-1 score\")\n",
        "print( \" Model 3: \\t\",round(acc3,3),\"\\t\\t\\t\",round(p3,3),\"\\t\\t\\t\\t\",round(r3,3),\"\\t\\t\\t\\t\",round(f3,3),\n",
        "      \"\\n Model 2: \\t\",round(acc2,3),\"\\t\\t\\t\",round(p2,3),\"\\t\\t\\t\\t\",round(r2,3),\"\\t\\t\\t\\t\",round(f2,3),\n",
        "      \"\\n Model 1: \\t\",round(acc1,3),\"\\t\\t\\t\",round(p1,3),\"\\t\\t\\t\\t\",round(r1,3),\"\\t\\t\\t\\t\",round(f1,3),\n",
        "      \"\\n Combined: \\t\", round(acc4,3),\"\\t\\t\\t\",round(p4,3),\"\\t\\t\\t\\t\",round(r4,3),\"\\t\\t\\t\\t\",round(f4,3))"
      ],
      "metadata": {
        "id": "zNwMD0qTV6Y3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}